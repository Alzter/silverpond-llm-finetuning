{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66057dd0-3155-4ca5-b7d3-4087416a4b99",
   "metadata": {},
   "source": [
    "# ▶️ Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604a738-c56d-4539-8813-d3506e872132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "ROOT_DIR = \"../data/eq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c19ec-61ce-415e-9251-4e396ba71ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules for LLM finetuning and evaluation\n",
    "import finetune as ft\n",
    "import evaluate as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f0f8e-3fe6-4aa6-88a2-abaf37506d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_prompts as prompts\n",
    "from evaluate import EvaluationConfig\n",
    "\n",
    "def evaluate_model(configurations, model, tokenizer, label_names, eval_dataset):\n",
    "    results = []\n",
    "    for config in configurations:\n",
    "        result = ev.evaluate(\n",
    "            model=model, tokenizer=tokenizer, label_names=label_names,\n",
    "            eval_dataset=dataset['test'], eval_config=config\n",
    "        )\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def save_results(results):\n",
    "    for result in results:\n",
    "        result.save(os.path.join(ROOT_DIR, \"results\")) # Saves to \"data/eq/results/<EvaluationConfig.name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44078c-dcfc-487f-80af-56e2dbc04682",
   "metadata": {},
   "source": [
    "# ▶️ Load EQ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34660a-9f23-47fc-8478-3268c68db277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv( os.path.join(ROOT_DIR, \"datasets/preprocessed_train.csv\"), low_memory=False )\n",
    "data_eval  = pd.read_csv( os.path.join(ROOT_DIR, \"datasets/preprocessed_eval.csv\"),  low_memory=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7745a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = [\n",
    "\"OUTAGE_ID\",\n",
    "\"WEATHER_CONDITION\",\n",
    "\"OUTAGE_CAUSE\",\n",
    "\"FAULT_LONG_DESCRIPTION\",\n",
    "\"SHORT_DESC_2\",\n",
    "\"WORK_ORDER_COMPONENT_CODE_DESCRIPTION\",\n",
    "\"OUTAGE_CAUSE_GROUP\",\n",
    "\"OUTAGE_STANDARD_REASON_DESCRIPTION\",\n",
    "\"REASON_FOR_INTERRUPTION\",\n",
    "\"PROVIDER\"\n",
    "]\n",
    "\n",
    "output_labels = [\n",
    "    \"MSSS_OBJECT_DESCRIPTION\",\n",
    "    \"MSSS_DAMAGE_DESCRIPTION\",\n",
    "    \"MSSS_CAUSE_DESCRIPTION\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958f4ab-8e51-4186-a009-473847765c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame into a Dataset\n",
    "dataset = ft.create_dataset_from_dataframe(data_train, input_features, output_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74907ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the dataset for testing purposes\n",
    "# dataset['train'] = dataset['train'].shard(5, 0) # First 20% of the train dataset\n",
    "# dataset['test'] = dataset['test'].shard(5, 0) # First 20% of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa4b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset into a form usable for supervised finetuning\n",
    "dataset, label_names = ft.preprocess_dataset(dataset,text_columns=input_features,label_columns=output_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8fe57-8936-4b78-a75b-1c31b8cedc1e",
   "metadata": {},
   "source": [
    "# ▶️ Load Baseline LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d26a1-5028-4f82-bfa4-f5ad3ebaed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "MODEL_DEVICE = \"cuda:0\"\n",
    "QUANTIZED = True # Load model with 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721a682-05ab-47c9-81ad-c17c28596e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# Same quantization configuration as QLoRA\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_compute_dtype = torch.float16\n",
    ") if QUANTIZED else None\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=MODEL_DEVICE,\n",
    "    use_cache=False # use_cache is incompatible with gradient checkpointing\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee3cf1-328f-4f9f-a3ad-7a0cd6fb057a",
   "metadata": {},
   "source": [
    "# ▶️ Evaluate Baseline LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b666b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(label_names.keys())\n",
    "values = list(label_names.values())\n",
    "PROMPT = f\"\"\"You are an expert at classifying power outage reports.\n",
    "\n",
    "You are given three classification tasks.\n",
    "You should output the result as a two json fields as {{\"MSSS_OBJECT_DESCRIPTION\" : \"object_label\", \"MSSS_DAMAGE_DESCRIPTION\" : \"damage_label\", \"MSSS_CAUSE_DESCRIPTION\" : \"cause_label\"}}\n",
    "For {labels[0]}, given the outage report, you are asked to classify it as one of the labels in the list {values[0]} and change object_label to the correct label in the list.\n",
    "For {labels[1]}, given the outage report, you are asked to classify it as one of the labels in the list {values[1]} and change damage_label to the correct label in the list.\n",
    "For {labels[2]}, given the outage report, you are asked to classify it as one of the labels in the list {values[2]} and change cause_label to the correct label in the list.\n",
    "\n",
    "Output the three json fields only and absolutely nothing else.\n",
    "Now it is your turn.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490271f-82e2-4c33-abb0-5f1cb695436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations for the baseline LLM\n",
    "baseline_configurations = [\n",
    "    EvaluationConfig(\n",
    "        name=\"Zero-shot Multi-task\",\n",
    "        prompt=PROMPT,\n",
    "        max_tokens=50\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e14f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = evaluate_model(baseline_configurations, model=model, tokenizer=tokenizer, label_names=label_names, eval_dataset=dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e74c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0eaf7f",
   "metadata": {},
   "source": [
    "# ▶️ Finetune LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7396b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_LLM_PATH = os.path.join(ROOT_DIR, \"models/Qwen2.5-FT-EQ-4\")\n",
    "\n",
    "LORA_RANK_DIMENSION = 6 # the rank of the adapter, the lower the fewer parameters you'll need to train. (smaller = more compression)\n",
    "LORA_ALPHA = 8 # this is the scaling factor for LoRA layers (higher = stronger adaptation)\n",
    "LORA_DROPOUT = 0.05 # dropout probability for LoRA layers (helps prevent overfitting)\n",
    "MAX_SEQ_LENGTH = 64\n",
    "EPOCHS=2\n",
    "LEARNING_RATE=2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd13482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_RANK_DIMENSION,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    bias=\"none\",\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    auto_find_batch_size=True,\n",
    "    \n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    packing=True,\n",
    "    \n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    optim='adamw_torch_fused',\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\", \n",
    "    \n",
    "    logging_steps=10,\n",
    "    logging_dir='./logs',\n",
    "    output_dir=FINETUNED_LLM_PATH,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ft.finetune( # Will save the model to the directory: FINETUNED_LLM_PATH\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    train_dataset=dataset['train'],\n",
    "    lora_config=lora_config, sft_config=sft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.to_csv(os.path.join(ROOT_DIR, \"results/loss_history.csv\"), index=False) # Save the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d8d8c-8447-4ad9-b267-a98072dccc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba130a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the training history and save the plot\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(history.set_index(\"step\")[\"loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "\n",
    "loss_max = math.ceil(history['loss'].max())\n",
    "plt.ylim([0, loss_max])\n",
    "\n",
    "plt.title(\"Fine-tuning Training History\")\n",
    "\n",
    "path = os.path.join(ROOT_DIR, \"results/loss_history.png\")\n",
    "plt.savefig( path, dpi=200, bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ef836",
   "metadata": {},
   "source": [
    "# ▶️ Load Finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddadc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unload the baseline model if it exists, otherwise we will probably get an OOM exception\n",
    "import gc, torch\n",
    "\n",
    "if \"bnb_config\" in locals(): del bnb_config\n",
    "if \"tokenizer\" in locals(): del tokenizer\n",
    "if \"model\" in locals(): del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINETUNED_LLM_PATH = os.path.join(ROOT_DIR, \"models/Qwen2.5-FT-EQ-1\")\n",
    "MODEL_DEVICE = \"cuda:0\"\n",
    "QUANTIZED = True # Load model with 4-bit quantization\n",
    "\n",
    "model, tokenizer = ft.load_finetuned_llm(FINETUNED_LLM_PATH, MODEL_DEVICE, QUANTIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed475c01",
   "metadata": {},
   "source": [
    "# ▶️ Evaluate Finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_configurations = [\n",
    "    EvaluationConfig(\n",
    "        name=\"Fine-tuned Multi-task\",\n",
    "        prompt=None,\n",
    "        max_tokens=50\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_results = evaluate_model(finetuned_configurations, model=model, tokenizer=tokenizer, label_names=label_names, eval_dataset=dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a364459",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(finetuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc760327-0662-441c-b092-54b5c5d27337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
