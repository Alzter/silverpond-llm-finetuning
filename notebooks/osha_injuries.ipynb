{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66057dd0-3155-4ca5-b7d3-4087416a4b99",
   "metadata": {},
   "source": [
    "# ▶️ Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604a738-c56d-4539-8813-d3506e872132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "ROOT_DIR = \"../data/osha/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c19ec-61ce-415e-9251-4e396ba71ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules for LLM finetuning and evaluation\n",
    "import finetune as ft\n",
    "import preprocess as pre\n",
    "import evaluate as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f0f8e-3fe6-4aa6-88a2-abaf37506d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_prompts as prompts\n",
    "from evaluate import EvaluationConfig\n",
    "\n",
    "def evaluate_model(configurations, model, tokenizer, label_names, eval_dataset):\n",
    "    results = []\n",
    "    for config in configurations:\n",
    "        result = ev.evaluate(\n",
    "            model=model, tokenizer=tokenizer, label_names=label_names,\n",
    "            eval_dataset=dataset['test'], eval_config=config\n",
    "        )\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def save_results(results):\n",
    "    for result in results:\n",
    "        result.save(os.path.join(ROOT_DIR, \"results/multi-class\")) # Saves to \"data/osha/results/<EvaluationConfig.name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44078c-dcfc-487f-80af-56e2dbc04682",
   "metadata": {},
   "source": [
    "# ▶️ Load and Preprocess OSHA Injuries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34660a-9f23-47fc-8478-3268c68db277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\n",
    "    os.path.join(ROOT_DIR, \"datasets/January2015toJuly2024.csv\"),\n",
    "    low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58179a-dc0a-433a-804b-0ade1cb0e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = \"Final Narrative\"\n",
    "output_labels = \"NatureTitle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958f4ab-8e51-4186-a009-473847765c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame into a Dataset\n",
    "balanced_dataset = pre.create_dataset_from_dataframe(data, input_features, output_labels, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c371de-6064-424d-afff-628857512159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select items from the 10 most common classes\n",
    "balanced_dataset = pre.select_top_n_classes(balanced_dataset, n=10, label_columns=output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e8700-fed5-4c52-9ea0-a85cf603ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = pre.undersample_dataset(balanced_dataset, label_columns=\"NatureTitle\", ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf662f64-d2d8-428a-9a80-5dbf195af04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset, labels = pre.class_decode_column(balanced_dataset, \"NatureTitle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e71dc-8cce-4c7a-b184-4b3dc22556f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = balanced_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c30b2a-3dca-45f2-b6f1-8d6a02213d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset.to_csv(os.path.join(ROOT_DIR, \"datasets/balanced.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad1a67-7db2-4682-9eb0-e3b1cf848e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset into a form usable for supervised finetuning\n",
    "\n",
    "dataset, label_names = pre.load_dataset(\n",
    "    os.path.join(ROOT_DIR, \"datasets/balanced.csv\"),\n",
    "    input_features,\n",
    "    output_labels,\n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74907ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the dataset for testing purposes\n",
    "dataset['train'] = dataset['train'].shard(5, 0) # First 20% of the train dataset\n",
    "dataset['test'] = dataset['test'].shard(10, 0) # First 10% of the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8fe57-8936-4b78-a75b-1c31b8cedc1e",
   "metadata": {},
   "source": [
    "# ▶️ Load Baseline LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d26a1-5028-4f82-bfa4-f5ad3ebaed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "MODEL_DEVICE = \"cuda:0\"\n",
    "QUANTIZED = True # Load model with 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721a682-05ab-47c9-81ad-c17c28596e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# Same quantization configuration as QLoRA\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_use_double_quant = True,\n",
    "    bnb_4bit_compute_dtype = torch.float16\n",
    ") if QUANTIZED else None\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=MODEL_DEVICE,\n",
    "    use_cache=False # use_cache is incompatible with gradient checkpointing\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee3cf1-328f-4f9f-a3ad-7a0cd6fb057a",
   "metadata": {},
   "source": [
    "# ▶️ Evaluate Baseline LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490271f-82e2-4c33-abb0-5f1cb695436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations for the baseline LLM\n",
    "baseline_configurations = [\n",
    "    EvaluationConfig(\n",
    "        technique_name=\"Zero-shot Multi-task\",\n",
    "        prompt=prompts.OSHA[\"MULTI_TASK\"],\n",
    "        max_tokens=40\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e14f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = evaluate_model(baseline_configurations, model=model, tokenizer=tokenizer, label_names=label_names, eval_dataset=dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e74c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0eaf7f",
   "metadata": {},
   "source": [
    "# ▶️ Finetune LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7396b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_LLM_PATH = os.path.join(ROOT_DIR, \"models/Qwen2.5-FT-OSHA-Injuries-Multiclass-2\")\n",
    "\n",
    "LORA_RANK_DIMENSION = 6 # the rank of the adapter, the lower the fewer parameters you'll need to train. (smaller = more compression)\n",
    "LORA_ALPHA = 8 # this is the scaling factor for LoRA layers (higher = stronger adaptation)\n",
    "LORA_DROPOUT = 0.05 # dropout probability for LoRA layers (helps prevent overfitting)\n",
    "MAX_SEQ_LENGTH = 64\n",
    "EPOCHS=1\n",
    "LEARNING_RATE=2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd13482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_RANK_DIMENSION,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    bias=\"none\",\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    auto_find_batch_size=True,\n",
    "    \n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    packing=True,\n",
    "    \n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    optim='adamw_torch_fused',\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\", \n",
    "    \n",
    "    logging_steps=10,\n",
    "    logging_dir='./logs',\n",
    "    output_dir=FINETUNED_LLM_PATH,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ft.finetune( # Will save the model to the directory: FINETUNED_LLM_PATH\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    train_dataset=dataset['train'],\n",
    "    lora_config=lora_config, sft_config=sft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.to_csv(os.path.join(ROOT_DIR, \"results/multi-class/loss_history.csv\"), index=False) # Save the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history and save the plot\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(history.set_index(\"Step\"))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "\n",
    "loss_max = math.ceil(history['Training Loss'].max())\n",
    "plt.ylim([0, loss_max])\n",
    "\n",
    "plt.title(\"Fine-tuning Training History\")\n",
    "\n",
    "path = os.path.join(ROOT_DIR, \"results/multi-class/loss_history.png\")\n",
    "plt.savefig( path, dpi=200, bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ef836",
   "metadata": {},
   "source": [
    "# ▶️ Load Finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddadc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unload the baseline model if it exists, otherwise we will probably get an OOM exception\n",
    "import gc, torch\n",
    "\n",
    "if \"bnb_config\" in locals(): del bnb_config\n",
    "if \"tokenizer\" in locals(): del tokenizer\n",
    "if \"model\" in locals(): del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_LLM_PATH = os.path.join(ROOT_DIR, \"models/Qwen2.5-FT-OSHA-Injuries-Multiclass-2\")\n",
    "MODEL_DEVICE = \"cuda:0\"\n",
    "QUANTIZED = True # Load model with 4-bit quantization\n",
    "\n",
    "model, tokenizer = ft.load_finetuned_llm(FINETUNED_LLM_PATH, MODEL_DEVICE, QUANTIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed475c01",
   "metadata": {},
   "source": [
    "# ▶️ Evaluate Finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_configurations = [\n",
    "    EvaluationConfig(\n",
    "        technique_name=\"Fine-tuned Multi-task\",\n",
    "        prompt=None,\n",
    "        max_tokens=40\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_results = evaluate_model(finetuned_configurations, model=model, tokenizer=tokenizer, label_names=label_names, eval_dataset=dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a364459",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(finetuned_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
