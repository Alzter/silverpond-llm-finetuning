{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66057dd0-3155-4ca5-b7d3-4087416a4b99",
   "metadata": {},
   "source": [
    "# ▶️ Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604a738-c56d-4539-8813-d3506e872132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "ROOT_DIR = \"../data/osha/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbff6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902c19ec-61ce-415e-9251-4e396ba71ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules for LLM finetuning and evaluation\n",
    "from utils import LocalModelArguments, LocalPLM\n",
    "import preprocess as pre\n",
    "import evaluate as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f0f8e-3fe6-4aa6-88a2-abaf37506d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_prompts as prompts\n",
    "from evaluate import EvaluationConfig\n",
    "\n",
    "def evaluate_model(configurations, model, label_names, eval_dataset):\n",
    "    results = []\n",
    "    for config in configurations:\n",
    "        result = ev.evaluate(\n",
    "            model=model, label_names=label_names,\n",
    "            eval_dataset=dataset['test'], eval_config=config\n",
    "        )\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def save_results(results):\n",
    "    for result in results:\n",
    "        result.save(os.path.join(ROOT_DIR, \"results\")) # Saves to \"data/osha/results/<EvaluationConfig.name>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44078c-dcfc-487f-80af-56e2dbc04682",
   "metadata": {},
   "source": [
    "# ▶️ Load and Preprocess OSHA Injuries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34660a-9f23-47fc-8478-3268c68db277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\n",
    "    os.path.join(ROOT_DIR, \"datasets/January2015toJuly2024.csv\"),\n",
    "    low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58179a-dc0a-433a-804b-0ade1cb0e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = \"Final Narrative\"\n",
    "output_labels = \"NatureTitle\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb4e26-2112-4507-920f-474bc5db02a6",
   "metadata": {},
   "source": [
    "## Imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd680a05-c3da-4fdf-a380-5494529c25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all classes with less than 50 samples\n",
    "min_class_size = 50\n",
    "while True:\n",
    "    class_counts = imbalanced_data[output_labels].value_counts()\n",
    "    classes_to_remove = class_counts.where(lambda x: x <= min_class_size).dropna().keys().to_list()\n",
    "    imbalanced_data = imbalanced_data[~imbalanced_data[output_labels].isin(classes_to_remove)]\n",
    "    \n",
    "    if imbalanced_data[output_labels].value_counts().where(lambda x: x <= min_class_size).dropna().size == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd1f7f-1af0-4330-8d45-6b4a9828d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_dataset = pre.create_dataset_from_dataframe(imbalanced_data, input_features, output_labels, test_size=0, encode_labels=False)\n",
    "imbalanced_dataset = imbalanced_dataset.to_pandas()\n",
    "imbalanced_dataset.to_csv(os.path.join(ROOT_DIR, \"datasets/imbalanced.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fdac8-0e76-4d23-b949-58109d257b3a",
   "metadata": {},
   "source": [
    "## Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958f4ab-8e51-4186-a009-473847765c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame into a Dataset\n",
    "balanced_dataset = pre.create_dataset_from_dataframe(data, input_features, output_labels, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c371de-6064-424d-afff-628857512159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select items from the 10 most common classes\n",
    "balanced_dataset = pre.select_top_n_classes(balanced_dataset, n=10, label_columns=output_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e8700-fed5-4c52-9ea0-a85cf603ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = pre.undersample_dataset(balanced_dataset, label_columns=\"NatureTitle\", ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf662f64-d2d8-428a-9a80-5dbf195af04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset, labels = pre.class_decode_column(balanced_dataset, \"NatureTitle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e71dc-8cce-4c7a-b184-4b3dc22556f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset = balanced_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c30b2a-3dca-45f2-b6f1-8d6a02213d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_dataset.to_csv(os.path.join(ROOT_DIR, \"datasets/balanced.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad1a67-7db2-4682-9eb0-e3b1cf848e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset into a form usable for supervised finetuning\n",
    "\n",
    "dataset, label_names = pre.load_dataset(\n",
    "    os.path.join(ROOT_DIR, \"datasets/balanced.csv\"),\n",
    "    input_features,\n",
    "    output_labels,\n",
    "    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74907ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the dataset for testing purposes\n",
    "dataset['train'] = dataset['train'].shard(5, 0) # First 20% of the train dataset\n",
    "dataset['test'] = dataset['test'].shard(10, 0) # First 10% of the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8fe57-8936-4b78-a75b-1c31b8cedc1e",
   "metadata": {},
   "source": [
    "# ▶️ Load Baseline LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707bc931-c3be-4ce1-b3ec-3340371f25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = LocalModelArguments(\n",
    "    model_name_or_path = \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    cuda_devices = \"1\",\n",
    "    use_4bit_quantization = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = \"float16\",\n",
    "    use_nested_quant = True,\n",
    "    use_reentrant = True\n",
    ")\n",
    "\n",
    "model = LocalPLM(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee3cf1-328f-4f9f-a3ad-7a0cd6fb057a",
   "metadata": {},
   "source": [
    "# ▶️ Evaluate Baseline LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490271f-82e2-4c33-abb0-5f1cb695436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations for the baseline LLM\n",
    "baseline_configurations = [\n",
    "    EvaluationConfig(\n",
    "        technique_name=\"Zero-shot Multi-task\",\n",
    "        prompt=prompts.OSHA[\"MULTI_TASK\"],\n",
    "        max_tokens=40\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e14f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = evaluate_model(baseline_configurations, model=model, label_names=label_names, eval_dataset=dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e74c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0eaf7f",
   "metadata": {},
   "source": [
    "# ▶️ Finetune LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7396b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_LLM_PATH = os.path.join(ROOT_DIR, \"models/Qwen2.5-FT-OSHA-Injuries-Multiclass-2\")\n",
    "\n",
    "LORA_RANK_DIMENSION = 6 # the rank of the adapter, the lower the fewer parameters you'll need to train. (smaller = more compression)\n",
    "LORA_ALPHA = 8 # this is the scaling factor for LoRA layers (higher = stronger adaptation)\n",
    "LORA_DROPOUT = 0.05 # dropout probability for LoRA layers (helps prevent overfitting)\n",
    "MAX_SEQ_LENGTH = 64\n",
    "EPOCHS=1\n",
    "LEARNING_RATE=2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd13482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_RANK_DIMENSION,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    bias=\"none\",\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    auto_find_batch_size=True,\n",
    "    \n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    packing=True,\n",
    "    \n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    optim='adamw_torch_fused',\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\", \n",
    "    \n",
    "    logging_steps=10,\n",
    "    logging_dir='./logs',\n",
    "    output_dir=FINETUNED_LLM_PATH,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55947bc8-7cd1-4d53-adb0-88ea818ae2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, history = model.finetune(\n",
    "    train_dataset=dataset['train'],\n",
    "    lora_config=lora_config, sft_config=sft_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.to_csv(os.path.join(ROOT_DIR, \"results/multi-class/loss_history.csv\"), index=False) # Save the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history and save the plot\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.plot(history.set_index(\"Step\"))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "\n",
    "loss_max = math.ceil(history['Training Loss'].max())\n",
    "plt.ylim([0, loss_max])\n",
    "\n",
    "plt.title(\"Fine-tuning Training History\")\n",
    "\n",
    "path = os.path.join(ROOT_DIR, \"results/multi-class/loss_history.png\")\n",
    "plt.savefig( path, dpi=200, bbox_inches='tight' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ef836",
   "metadata": {},
   "source": [
    "# ▶️ Load Finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddadc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unload the baseline model if it exists, otherwise we will probably get an OOM exception\n",
    "import gc, torch\n",
    "\n",
    "if \"model\" in locals(): del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd6055a-b63d-4871-bd95-4a4eec9ef9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = LocalModelArguments(\n",
    "    model_name_or_path = \"models/Qwen2.5-FT-OSHA-Injuries-Multiclass-2\",\n",
    "    cuda_devices = \"1\",\n",
    "    use_4bit_quantization = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = \"float16\",\n",
    "    use_nested_quant = False\n",
    ")\n",
    "\n",
    "model = LocalPLM(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed475c01",
   "metadata": {},
   "source": [
    "# ▶️ Evaluate Finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_configurations = [\n",
    "    EvaluationConfig(\n",
    "        technique_name=\"Fine-tuned Multi-task\",\n",
    "        prompt=None,\n",
    "        max_tokens=40\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_results = evaluate_model(finetuned_configurations, model=model, label_names=label_names, eval_dataset=dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a364459",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(finetuned_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
